{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950ad1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wallet Transaction Fetcher\n",
    "===========================================\n",
    "\n",
    "A cell‑oriented version of **wallet_fetcher** designed to be run inside\n",
    "Jupyter Lab/Notebook or VS Code.  Each `# %%` delimiter marks an executable\n",
    "cell.\n",
    "\n",
    "* Loads *wallets_classes.csv* and filters for class `2` (Elliptic licit).\n",
    "* Skips wallets already downloaded to *wallets/elliptic_licit*.\n",
    "* Uses a **rotating proxy** (placeholder `http://YOUR_ROTATING_PROXY`).  Set\n",
    "  the real gateway via env‑var `ROTATING_PROXY_URL`.\n",
    "* Handles `429`/`50x` with exponential back‑off.\n",
    "* Persists failures to `failed_wallets.json` so you can rerun the last cell\n",
    "  to retry.\n",
    "\"\"\"\n",
    "# %%\n",
    "from __future__ import annotations\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from typing import List, Sequence\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696cf20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"wallets_classes.csv\"  # input CSV with `address, class` columns\n",
    "CLASS_FILTER = 2                   # keep only this class label\n",
    "\n",
    "OUTPUT_DIR = Path(\"wallets/elliptic_licit\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Rotating proxy gateway – replace or export ROTATING_PROXY_URL\n",
    "PROXY_URL = os.getenv(\"ROTATING_PROXY_URL\", \"http://YOUR_ROTATING_PROXY\")\n",
    "\n",
    "MAX_WORKERS = 5            # parallel threads\n",
    "BATCH_SIZE = 50            # wallets per batch\n",
    "DELAY_BETWEEN_BATCHES = 2  # seconds between batches\n",
    "REQUEST_TIMEOUT = 30       # HTTP timeout (s)\n",
    "MAX_RETRIES = 3            # per‑request retries\n",
    "BACKOFF_FACTOR = 1.5       # exponential back‑off multiplier\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Load & filter wallet list\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def load_wallets(csv_path: str, wallet_class: int) -> List[str]:\n",
    "    \"\"\"Return wallet addresses whose *class* equals *wallet_class*.\"\"\"\n",
    "    with open(csv_path, newline=\"\") as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        return [row[\"address\"] for row in reader if int(row[\"class\"]) == wallet_class]\n",
    "\n",
    "\n",
    "def already_downloaded(out_dir: Path) -> set[str]:\n",
    "    pattern = re.compile(r\"(.+)_transactions\\\\.json$\")\n",
    "    return {\n",
    "        pattern.match(p.name).group(1)\n",
    "        for p in out_dir.glob(\"*_transactions.json\")\n",
    "        if pattern.match(p.name)\n",
    "    }\n",
    "\n",
    "wallets_all = load_wallets(DATA_FILE, CLASS_FILTER)\n",
    "wallets_done = already_downloaded(OUTPUT_DIR)\n",
    "wallets_to_process = [w for w in wallets_all if w not in wallets_done]\n",
    "\n",
    "print(f\"{len(wallets_done)} / {len(wallets_all)} wallets already downloaded\")\n",
    "print(f\"{len(wallets_to_process)} queued for processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92684ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Helper functions – HTTP with retry & save\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def _request_with_retry(session: requests.Session, url: str, retries: int = MAX_RETRIES):\n",
    "    \"\"\"GET *url* with exponential back‑off on 429/5xx/network errors.\"\"\"\n",
    "    attempt = 0\n",
    "    while attempt <= retries:\n",
    "        try:\n",
    "            resp = session.get(url, timeout=REQUEST_TIMEOUT)\n",
    "            if resp.status_code == 200:\n",
    "                return resp\n",
    "            if resp.status_code in (429, 500, 502, 503, 504):\n",
    "                delay = BACKOFF_FACTOR ** attempt\n",
    "                print(f\"⚠️ HTTP {resp.status_code} – retrying in {delay:.1f}s\")\n",
    "                time.sleep(delay)\n",
    "            else:\n",
    "                print(f\"❌ Unhandled status {resp.status_code} – skipping\")\n",
    "                return None\n",
    "        except requests.RequestException as exc:\n",
    "            delay = BACKOFF_FACTOR ** attempt\n",
    "            print(f\"⚠️ {type(exc).__name__}: {exc} – retrying in {delay:.1f}s\")\n",
    "            time.sleep(delay)\n",
    "        attempt += 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def fetch_and_save(wallet: str, out_dir: Path, session: requests.Session) -> bool:\n",
    "    url = f\"https://blockchain.info/rawaddr/{wallet}\"\n",
    "    resp = _request_with_retry(session, url)\n",
    "    if resp and resp.status_code == 200:\n",
    "        out_path = out_dir / f\"{wallet}_transactions.json\"\n",
    "        out_path.write_text(json.dumps(resp.json(), indent=2))\n",
    "        print(f\"✅ Saved: {out_path.name}\")\n",
    "        return True\n",
    "    print(f\"❌ Failed: {wallet}\")\n",
    "    return False\n",
    "\n",
    "\n",
    "def process_wallets(wallets: Sequence[str], out_dir: Path):\n",
    "    failed = []\n",
    "    proxy_dict = {\"http\": PROXY_URL, \"https\": PROXY_URL} if PROXY_URL else None\n",
    "    with requests.Session() as session:\n",
    "        if proxy_dict:\n",
    "            session.proxies.update(proxy_dict)\n",
    "\n",
    "        for batch_no, batch_start in enumerate(range(0, len(wallets), BATCH_SIZE), start=1):\n",
    "            batch = wallets[batch_start : batch_start + BATCH_SIZE]\n",
    "            print(f\"\\n=== Batch {batch_no} – {len(batch)} wallets ===\")\n",
    "            with ThreadPoolExecutor(max_workers=MAX_WORKERS) as pool:\n",
    "                futures = {pool.submit(fetch_and_save, w, out_dir, session): w for w in batch}\n",
    "                for fut in as_completed(futures):\n",
    "                    if not fut.result():\n",
    "                        failed.append(futures[fut])\n",
    "\n",
    "            if batch_start + BATCH_SIZE < len(wallets):\n",
    "                print(f\"⏱️ Sleeping {DELAY_BETWEEN_BATCHES}s before next batch…\")\n",
    "                time.sleep(DELAY_BETWEEN_BATCHES)\n",
    "    return failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c60570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Execute download – run this cell\n",
    "# ----------------------------------------------------------------------\n",
    "failed_wallets = process_wallets(wallets_to_process, OUTPUT_DIR)\n",
    "\n",
    "if failed_wallets:\n",
    "    failed_path = OUTPUT_DIR / \"failed_wallets.json\"\n",
    "    failed_path.write_text(json.dumps(sorted(failed_wallets), indent=2))\n",
    "    print(f\"\\nℹ️  Wrote failed wallets list to {failed_path}\")\n",
    "\n",
    "print(f\"\\n✔️ Completed. Success: {len(wallets_to_process) - len(failed_wallets)}, Failed: {len(failed_wallets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc748201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Retry block – rerun to process failed_wallets.json\n",
    "# ----------------------------------------------------------------------\n",
    "retry_path = OUTPUT_DIR / \"failed_wallets.json\"\n",
    "if retry_path.exists():\n",
    "    wallets_retry = json.loads(retry_path.read_text())\n",
    "    print(f\"Retrying {len(wallets_retry)} wallets…\")\n",
    "    failed_wallets = process_wallets(wallets_retry, OUTPUT_DIR)\n",
    "    if failed_wallets:\n",
    "        retry_path.write_text(json.dumps(sorted(failed_wallets), indent=2))\n",
    "        print(f\"Updated failed list – {len(failed_wallets)} wallets remain\")\n",
    "    else:\n",
    "        retry_path.unlink()\n",
    "        print(\"All retries succeeded – failed_wallets.json removed\")\n",
    "else:\n",
    "    print(\"No failed_wallets.json found – nothing to retry.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
