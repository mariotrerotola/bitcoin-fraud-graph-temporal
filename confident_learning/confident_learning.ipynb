{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d92f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLabel Noise Detection with Cleanlab – Jupyter Edition\\n====================================================\\n\\nThis notebook identifies potentially mislabeled entries in a binary fraud vs.\\nlicit dataset using **Cleanlab**’s `find_label_issues` function. It then\\nre-trains a RandomForest on the cleaned subset to compare F1 performance.\\n\\nSteps:\\n1. Install required packages (`cleanlab`, `tqdm`, `matplotlib`).\\n2. Load dataset from `DATA_PATH`; ensure fraud=1, licit=0 mapping.\\n3. Train baseline RandomForest and compute F1 on a hold-out set.\\n4. Perform 5‑fold CV `predict_proba` on full data; flag low-confidence labels\\n   via Cleanlab.\\n5. Remove suspect rows, retrain RF, and report Δ F1.\\n6. Display top 10 suspect indices and plot noise vs clean counts.\\n7. Perform 3D PCA on full feature set and visualize suspect vs clean samples.\\n\\n> **Note:** Adjust `DATA_PATH`, `CV_FOLDS`, and `RANDOM_STATE` as needed.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Label Noise Detection with Cleanlab – Jupyter Edition\n",
    "====================================================\n",
    "\n",
    "This notebook identifies potentially mislabeled entries in a binary fraud vs.\n",
    "licit dataset using **Cleanlab**’s `find_label_issues` function. It then\n",
    "re-trains a RandomForest on the cleaned subset to compare F1 performance.\n",
    "\n",
    "Steps:\n",
    "1. Install required packages (`cleanlab`, `tqdm`, `matplotlib`).\n",
    "2. Load dataset from `DATA_PATH`; ensure fraud=1, licit=0 mapping.\n",
    "3. Train baseline RandomForest and compute F1 on a hold-out set.\n",
    "4. Perform 5‑fold CV `predict_proba` on full data; flag low-confidence labels\n",
    "   via Cleanlab.\n",
    "5. Remove suspect rows, retrain RF, and report Δ F1.\n",
    "6. Display top 10 suspect indices and plot noise vs clean counts.\n",
    "7. Perform 3D PCA on full feature set and visualize suspect vs clean samples.\n",
    "\n",
    "> **Note:** Adjust `DATA_PATH`, `CV_FOLDS`, and `RANDOM_STATE` as needed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527bd456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q cleanlab tqdm matplotlib scikit-learn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1845464c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dexire/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Dataset not found: ../../../data/dataset_with_label/chainabuse/chainabuse_fraud_elliptic_licit_processed.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Verify dataset path exists\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DATA_PATH\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDATA_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Dataset not found: ../../../data/dataset_with_label/chainabuse/chainabuse_fraud_elliptic_licit_processed.csv"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 1. Imports & configuration\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cleanlab.filter import find_label_issues\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_predict, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configuration ---------------------------------------------------------------\n",
    "BASE_DIR = Path(\"../../../data/dataset_with_label\")\n",
    "USE_CASE  = \"chainabuse\"\n",
    "FILE_NAME = \"chainabuse_fraud_elliptic_licit_processed.csv\"\n",
    "DATA_PATH = BASE_DIR / USE_CASE / FILE_NAME\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 42\n",
    "CV_FOLDS = 5\n",
    "\n",
    "# Logging ---------------------------------------------------------------------\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "log = logging.getLogger(\"cleanlab-pipeline\")\n",
    "\n",
    "# Verify dataset path exists\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efbb764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:04:34,430 [INFO] Label encoding: ['fraud', 'licit'] -> [0,1] if fraud at index1? False\n",
      "2025-06-04 10:04:34,431 [INFO] Class counts: {0: 7152, 1: 6343}\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 2. Load dataset and map labels\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "if \"class\" not in df.columns:\n",
    "    raise KeyError(\"Column 'class' not found in dataset\")\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df[\"class\"])  # Expecting labels {\"fraud\",\"licit\"}\n",
    "\n",
    "# Ensure fraud=1, licit=0 ------------------------------------------------------\n",
    "if set(le.classes_) != {\"fraud\", \"licit\"}:\n",
    "    raise ValueError(\"Expected labels 'fraud' and 'licit' only\")\n",
    "\n",
    "fraud_is_index1 = list(le.classes_).index(\"fraud\") == 1\n",
    "labels = le.transform(df[\"class\"])  # 0/1 but check order\n",
    "if not fraud_is_index1:\n",
    "    labels = 1 - labels  # Flip so fraud=1, licit=0\n",
    "log.info(\"Label encoding: %s -> [0,1] if fraud at index1? %s\", list(le.classes_), fraud_is_index1)\n",
    "log.info(\"Class counts: %s\", dict(pd.Series(labels).value_counts()))\n",
    "\n",
    "df[\"y\"] = labels\n",
    "X = df.drop(columns=[\"class\", \"y\"]).values\n",
    "y = df[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04437b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:04:38,759 [INFO] Baseline F1 on hold-out set: 0.909\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 3. Train/test split & baseline RandomForest\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "baseline_f1 = f1_score(y_test, y_pred)\n",
    "log.info(\"Baseline F1 on hold‑out set: %.3f\", baseline_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f604ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-04 10:04:38,763 [INFO] Running 5-fold CV predict_proba on full dataset…\n",
      "2025-06-04 10:04:45,794 [INFO] Detected 306 suspect labels (2.27% of data)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 4. Cleanlab: detect potential label issues via cross‑validated predict_proba\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "log.info(\"Running %s‑fold CV predict_proba on full dataset…\", CV_FOLDS)\n",
    "probs_full = cross_val_predict(clf, X, y, cv=CV_FOLDS, method=\"predict_proba\", n_jobs=-1)\n",
    "\n",
    "noise_indices = find_label_issues(labels=y, pred_probs=probs_full, return_indices_ranked_by=\"self_confidence\")\n",
    "noise_rate = len(noise_indices) / len(y)\n",
    "log.info(\"Detected %s suspect labels (%.2f%% of data)\", len(noise_indices), 100 * noise_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77861704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 5. Remove suspect rows and retrain RandomForest on cleaned subset\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "mask_clean = np.ones(len(y), dtype=bool)\n",
    "mask_clean[noise_indices] = False\n",
    "\n",
    "X_clean = X[mask_clean]\n",
    "y_clean = y[mask_clean]\n",
    "\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(\n",
    "    X_clean, y_clean, test_size=TEST_SIZE, stratify=y_clean, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "clf_clean = RandomForestClassifier(n_estimators=200, max_depth=20, class_weight=\"balanced\", random_state=RANDOM_STATE)\n",
    "clf_clean.fit(Xc_train, yc_train)\n",
    "\n",
    "yc_pred = clf_clean.predict(Xc_test)\n",
    "clean_f1 = f1_score(yc_test, yc_pred)\n",
    "log.info(\"F1 after removing suspect labels: %.3f (Δ = %.3f)\", clean_f1, clean_f1 - baseline_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c081c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 6. Display top 10 suspect indices and plot noise vs clean counts\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"Top 10 indices flagged as potential label errors:\")\n",
    "print(noise_indices[:10])\n",
    "\n",
    "# Plot count of suspect vs clean labels\n",
    "total = len(y)\n",
    "num_suspect = len(noise_indices)\n",
    "num_clean = total - num_suspect\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar([\"Clean\",\"Suspect\"], [num_clean, num_suspect], color=[\"#4CAF50\", \"#F44336\"])\n",
    "plt.title(\"Label Noise: Clean vs Suspect Samples\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc8248",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 7. Interactive 3D PCA visualization with Plotly\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Fit PCA to full feature set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------\n",
    "# 7. Interactive 3D PCA visualization with Plotly\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "# Fit PCA to full feature set\n",
    "pca = PCA(n_components=3, random_state=RANDOM_STATE)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Create DataFrame for plotting\n",
    "df_plot = pd.DataFrame(\n",
    "    X_pca, columns=[\"PC1\", \"PC2\", \"PC3\"],\n",
    ")\n",
    "# Add label type: Clean vs Suspect\n",
    "labels_type = np.where(mask_suspect, \"Suspect\", \"Clean\")\n",
    "df_plot[\"LabelType\"] = labels_type\n",
    "\n",
    "# Interactive 3D scatter\n",
    "fig = px.scatter_3d(\n",
    "    df_plot,\n",
    "    x=\"PC1\", y=\"PC2\", z=\"PC3\",\n",
    "    color=\"LabelType\",\n",
    "    color_discrete_map={\"Clean\": \"#4CAF50\", \"Suspect\": \"#F44336\"},\n",
    "    title=\"Interactive 3D PCA: Clean vs Suspect Samples\",\n",
    "    opacity=0.7,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title=\"PC1\",\n",
    "    yaxis_title=\"PC2\",\n",
    "    zaxis_title=\"PC3\"\n",
    "))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dexire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
